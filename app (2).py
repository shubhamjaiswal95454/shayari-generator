import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

st.title("üìù Free Shayari Generator (Hugging Face - mT5 Model)")

keywords = st.text_input("Enter keywords for your Shayari (comma separated):", "")
recipient = st.selectbox("Who is the Shayari for?", ["Friend", "Lover", "Family", "Anyone"])
generate = st.button("Generate Shayari")

@st.cache_resource
def load_model():
    model_name = "google/mt5-small"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return tokenizer, model

if generate and keywords.strip():
    with st.spinner("Generating Shayari..."):
        tokenizer, model = load_model()
        prompt = (
            f"{recipient} ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§æ‡§Ø‡§∞‡•Ä ‡§≤‡§ø‡§ñ‡•á‡§Ç ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§Ø‡•á ‡§∂‡§¨‡•ç‡§¶ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•ã‡§Ç: {keywords}‡•§"
            " ‡§á‡§∏‡•á ‡§ï‡§æ‡§µ‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ‡§ï ‡§î‡§∞ ‡§∏‡§æ‡§∞‡•ç‡§•‡§ï ‡§∞‡§ñ‡•á‡§Ç‡•§"
        )
        input_ids = tokenizer(prompt, return_tensors="pt").input_ids
        output_ids = model.generate(input_ids, max_length=64, temperature=0.9)
        shayari = tokenizer.decode(output_ids[0], skip_special_tokens=True)
        st.subheader("‚ú® ‡§Ü‡§™‡§ï‡•Ä ‡§∂‡§æ‡§Ø‡§∞‡•Ä:")
        st.write(shayari)
else:
    st.info("‡§∂‡§æ‡§Ø‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Ä‡§µ‡§∞‡•ç‡§°‡•ç‡§∏ ‡§°‡§æ‡§≤‡•á‡§Ç ‡§î‡§∞ Generate Shayari ‡§¶‡§¨‡§æ‡§è‡§Å‡•§")
